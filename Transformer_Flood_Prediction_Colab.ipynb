{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Fine-Tuning for Coastal Flood Prediction\n",
    "\n",
    "**iHARP ML Challenge 2 - Deep Learning Approach**\n",
    "\n",
    "This notebook implements a transfer learning approach using pre-trained transformers fine-tuned on 70 years of coastal flooding data.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    PRE-TRAINED TRANSFORMER                       │\n",
    "│  (50% - General time series knowledge from diverse domains)     │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│  Options:                                                        │\n",
    "│  - Chronos (Amazon): T5-based, 27B observations                 │\n",
    "│  - Custom Transformer: Trained from scratch for comparison      │\n",
    "│  - LSTM Baseline: For RNN comparison                            │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ Fine-tuning\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                 FLOODING DOMAIN ADAPTATION                       │\n",
    "│  (50% - 70 years of sea level data, 12 coastal stations)        │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## Training Strategy for 50/50 Balance\n",
    "\n",
    "1. **Phase 1 (Epochs 1-3)**: Freeze transformer backbone, train classification head only\n",
    "2. **Phase 2 (Epochs 4+)**: Unfreeze all layers, fine-tune with low learning rate\n",
    "\n",
    "This preserves ~50% of the pre-trained general knowledge while adapting ~50% to flooding patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# VERSION STAMP - MANDATORY VERIFICATION CELL\n# =============================================================================\nimport subprocess, datetime, os, textwrap\nprint(\"=\" * 70)\nprint(\"✅ FLOOD NOTEBOOK UPDATED: v2025-12-15-CLAUDE-PATCH-01\")\nprint(\"=\" * 70)\nprint(\"Timestamp:\", datetime.datetime.utcnow().isoformat(), \"UTC\")\ntry:\n    print(\"Git commit:\", subprocess.check_output([\"git\",\"rev-parse\",\"--short\",\"HEAD\"]).decode().strip())\nexcept Exception as e:\n    print(\"Git commit: unavailable\", e)\nprint(\"CWD:\", os.getcwd())\nprint(\"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch transformers scipy pandas numpy scikit-learn matplotlib\n",
    "!pip install -q chronos-forecasting  # Amazon's time series foundation model\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    print(\"Using CPU (training will be slower)\")\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset file\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Please upload 'NEUSTG_19502020_12stations.mat' file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Verify upload\n",
    "import os\n",
    "if 'NEUSTG_19502020_12stations.mat' in uploaded:\n",
    "    print(\"\\nDataset uploaded successfully!\")\n",
    "else:\n",
    "    print(\"\\nPlease upload the correct .mat file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, f1_score,\n",
    "    matthews_corrcoef, mean_squared_error, mean_absolute_error,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Transformers\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Modify these parameters as needed\n",
    "# =============================================================================\n",
    "\n",
    "# Data settings\n",
    "HIST_DAYS = 7          # Input window: 7 days of historical data\n",
    "FUTURE_DAYS = 14       # Prediction window: predict flooding in next 14 days\n",
    "\n",
    "# Station splits (matches competition)\n",
    "TRAIN_STATIONS = [\n",
    "    'Annapolis', 'Atlantic_City', 'Charleston', 'Washington',\n",
    "    'Wilmington', 'Eastport', 'Portland', 'Sewells_Point', 'Sandy_Hook'\n",
    "]\n",
    "TEST_STATIONS = ['Lewes', 'Fernandina_Beach', 'The_Battery']\n",
    "\n",
    "# Model hyperparameters\n",
    "D_MODEL = 128          # Transformer hidden dimension\n",
    "N_HEADS = 8            # Number of attention heads\n",
    "N_LAYERS = 4           # Number of transformer layers\n",
    "DROPOUT = 0.1          # Dropout rate\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 64        # Batch size\n",
    "LEARNING_RATE = 1e-4   # Learning rate (low for fine-tuning)\n",
    "EPOCHS = 50            # Maximum epochs\n",
    "PATIENCE = 10          # Early stopping patience\n",
    "WEIGHT_DECAY = 0.01    # L2 regularization\n",
    "WARMUP_RATIO = 0.1     # Learning rate warmup\n",
    "\n",
    "# 50/50 Balance settings\n",
    "FREEZE_EPOCHS = 3      # Epochs to freeze backbone (Phase 1)\n",
    "\n",
    "print(\"Configuration loaded!\")\n",
    "print(f\"\\nModel: Transformer with d_model={D_MODEL}, heads={N_HEADS}, layers={N_LAYERS}\")\n",
    "print(f\"Training: {EPOCHS} epochs, batch_size={BATCH_SIZE}, lr={LEARNING_RATE}\")\n",
    "print(f\"50/50 Strategy: Freeze backbone for first {FREEZE_EPOCHS} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matlab2datetime(matlab_datenum):\n",
    "    \"\"\"Convert MATLAB datenum to Python datetime.\"\"\"\n",
    "    return datetime.fromordinal(int(matlab_datenum)) \\\n",
    "           + timedelta(days=matlab_datenum % 1) \\\n",
    "           - timedelta(days=366)\n",
    "\n",
    "def load_data(filepath='NEUSTG_19502020_12stations.mat'):\n",
    "    \"\"\"Load the .mat dataset.\"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    data = loadmat(filepath)\n",
    "    \n",
    "    lat = data['lattg'].flatten()\n",
    "    lon = data['lontg'].flatten()\n",
    "    sea_level = data['sltg']\n",
    "    station_names = [s[0] for s in data['sname'].flatten()]\n",
    "    time_raw = data['t'].flatten()\n",
    "    time_dt = pd.to_datetime([matlab2datetime(t) for t in time_raw])\n",
    "    \n",
    "    print(f\"Loaded {len(station_names)} stations\")\n",
    "    print(f\"Time range: {time_dt[0]} to {time_dt[-1]}\")\n",
    "    print(f\"Total hourly observations: {len(time_dt):,}\")\n",
    "    \n",
    "    # Build DataFrame\n",
    "    records = []\n",
    "    for i, stn in enumerate(station_names):\n",
    "        for j, t in enumerate(time_dt):\n",
    "            records.append({\n",
    "                'time': t,\n",
    "                'station_name': stn,\n",
    "                'latitude': lat[i],\n",
    "                'longitude': lon[i],\n",
    "                'sea_level': sea_level[j, i]\n",
    "            })\n",
    "    \n",
    "    df_hourly = pd.DataFrame(records)\n",
    "    print(f\"Built hourly DataFrame: {len(df_hourly):,} rows\")\n",
    "    \n",
    "    return df_hourly, station_names\n",
    "\n",
    "# Load the data\n",
    "df_hourly, station_names = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_daily_with_labels(df_hourly):\n",
    "    \"\"\"Aggregate to daily data and compute flood labels.\"\"\"\n",
    "    print(\"\\nComputing daily aggregates...\")\n",
    "    \n",
    "    # Flood thresholds per station (mean + 1.5 * std)\n",
    "    threshold_df = df_hourly.groupby('station_name')['sea_level'].agg(['mean', 'std']).reset_index()\n",
    "    threshold_df['flood_threshold'] = threshold_df['mean'] + 1.5 * threshold_df['std']\n",
    "    \n",
    "    df_hourly = df_hourly.merge(\n",
    "        threshold_df[['station_name', 'flood_threshold']],\n",
    "        on='station_name', how='left'\n",
    "    )\n",
    "    \n",
    "    # Daily aggregation\n",
    "    df_daily = df_hourly.groupby(['station_name', pd.Grouper(key='time', freq='D')]).agg({\n",
    "        'sea_level': 'mean',\n",
    "        'latitude': 'first',\n",
    "        'longitude': 'first',\n",
    "        'flood_threshold': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Daily max for flood detection\n",
    "    hourly_max = df_hourly.groupby(\n",
    "        ['station_name', pd.Grouper(key='time', freq='D')]\n",
    "    )['sea_level'].max().reset_index()\n",
    "    \n",
    "    df_daily = df_daily.merge(hourly_max, on=['station_name', 'time'], suffixes=('', '_max'))\n",
    "    df_daily['flood'] = (df_daily['sea_level_max'] > df_daily['flood_threshold']).astype(int)\n",
    "    \n",
    "    # Sort by station and time\n",
    "    df_daily = df_daily.sort_values(['station_name', 'time']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Daily DataFrame: {len(df_daily):,} rows\")\n",
    "    print(f\"Overall flood rate: {df_daily['flood'].mean():.2%}\")\n",
    "    \n",
    "    return df_daily, threshold_df\n",
    "\n",
    "df_daily, threshold_df = compute_daily_with_labels(df_hourly)\n",
    "\n",
    "# Show flood thresholds\n",
    "print(\"\\nFlood thresholds per station:\")\n",
    "display(threshold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df_daily, stations, seq_len=HIST_DAYS, pred_len=FUTURE_DAYS):\n",
    "    \"\"\"Create sequence windows for transformer input.\"\"\"\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    metadata = []\n",
    "    \n",
    "    for stn in stations:\n",
    "        grp = df_daily[df_daily['station_name'] == stn].sort_values('time').reset_index(drop=True)\n",
    "        sea_levels = grp['sea_level'].values\n",
    "        floods = grp['flood'].values\n",
    "        times = grp['time'].values\n",
    "        \n",
    "        for i in range(len(grp) - seq_len - pred_len + 1):\n",
    "            # Input sequence: 7 days of sea level\n",
    "            seq = sea_levels[i:i+seq_len]\n",
    "            \n",
    "            # Skip if any NaN\n",
    "            if np.isnan(seq).any():\n",
    "                continue\n",
    "            \n",
    "            # Label: any flood in next 14 days\n",
    "            future_floods = floods[i+seq_len:i+seq_len+pred_len]\n",
    "            label = int(future_floods.max() > 0)\n",
    "            \n",
    "            sequences.append(seq)\n",
    "            labels.append(label)\n",
    "            metadata.append({\n",
    "                'station': stn,\n",
    "                'start_time': times[i],\n",
    "                'end_time': times[i+seq_len-1]\n",
    "            })\n",
    "    \n",
    "    return np.array(sequences), np.array(labels), metadata\n",
    "\n",
    "# Create sequences from training stations\n",
    "print(f\"\\nCreating sequences from {len(TRAIN_STATIONS)} training stations...\")\n",
    "X, y, metadata = create_sequences(df_daily, TRAIN_STATIONS)\n",
    "\n",
    "print(f\"Total sequences: {len(X):,}\")\n",
    "print(f\"Sequence shape: {X.shape}\")\n",
    "print(f\"Positive (flood) rate: {y.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Validation Split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 80/20 TRAIN/VALIDATION SPLIT (as required by homework)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPLITTING DATA: 80% TRAIN / 20% VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,          # 20% validation\n",
    "    random_state=42,\n",
    "    stratify=y               # Maintain class balance\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set:   {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(X_val):,} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTrain positive rate: {y_train.mean():.2%}\")\n",
    "print(f\"Val positive rate:   {y_val.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PyTorch Dataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for flood prediction sequences.\"\"\"\n",
    "    \n",
    "    def __init__(self, sequences, labels, normalize=True):\n",
    "        self.sequences = sequences.astype(np.float32)\n",
    "        self.labels = labels.astype(np.float32)\n",
    "        \n",
    "        if normalize:\n",
    "            # Z-score normalization per sequence\n",
    "            self.mean = np.mean(self.sequences, axis=1, keepdims=True)\n",
    "            self.std = np.std(self.sequences, axis=1, keepdims=True) + 1e-8\n",
    "            self.sequences = (self.sequences - self.mean) / self.std\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.sequences[idx]),\n",
    "            torch.tensor(self.labels[idx])\n",
    "        )\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FloodDataset(X_train, y_train)\n",
    "val_dataset = FloodDataset(X_val, y_val)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture\n",
    "\n",
    "### Transformer Architecture for Time Series Classification\n",
    "\n",
    "```\n",
    "Input: Sea level sequence (7 days)\n",
    "    │\n",
    "    ▼\n",
    "┌─────────────────────────────────┐\n",
    "│   Input Projection (Linear)     │  Project to d_model dimensions\n",
    "└─────────────────────────────────┘\n",
    "    │\n",
    "    ▼\n",
    "┌─────────────────────────────────┐\n",
    "│   Positional Encoding           │  Add temporal position information\n",
    "│   (Sinusoidal)                  │\n",
    "└─────────────────────────────────┘\n",
    "    │\n",
    "    ▼\n",
    "┌─────────────────────────────────┐\n",
    "│   Transformer Encoder           │  N layers of:\n",
    "│   ├─ Multi-Head Self-Attention  │  - Capture temporal dependencies\n",
    "│   ├─ Add & Norm                 │  - Residual connections\n",
    "│   ├─ Feed-Forward Network       │  - Non-linear transformations\n",
    "│   └─ Add & Norm                 │\n",
    "└─────────────────────────────────┘\n",
    "    │\n",
    "    ▼\n",
    "┌─────────────────────────────────┐\n",
    "│   Global Average Pooling        │  Aggregate sequence information\n",
    "└─────────────────────────────────┘\n",
    "    │\n",
    "    ▼\n",
    "┌─────────────────────────────────┐\n",
    "│   Classification Head           │  MLP with dropout\n",
    "│   ├─ Linear(d_model → d_model/2)│\n",
    "│   ├─ ReLU + Dropout             │\n",
    "│   └─ Linear(d_model/2 → 1)      │\n",
    "└─────────────────────────────────┘\n",
    "    │\n",
    "    ▼\n",
    "Output: Flood probability (0-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFloodClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer for Flood Classification\n",
    "    \n",
    "    Designed to be:\n",
    "    1. Pre-trained on general patterns (or use pre-trained weights)\n",
    "    2. Fine-tuned on flooding data with 50/50 balance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=1,           # Sea level (univariate)\n",
    "        d_model=128,           # Transformer hidden dimension\n",
    "        nhead=8,               # Number of attention heads\n",
    "        num_layers=4,          # Number of transformer layers\n",
    "        dim_feedforward=512,   # FFN dimension\n",
    "        dropout=0.1,\n",
    "        max_seq_len=100\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Positional encoding (sinusoidal)\n",
    "        self.pos_encoding = self._generate_positional_encoding(max_seq_len, d_model)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def _generate_positional_encoding(self, max_len, d_model):\n",
    "        \"\"\"Generate sinusoidal positional encodings.\"\"\"\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return nn.Parameter(pe.unsqueeze(0), requires_grad=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len) or (batch, seq_len, 1)\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(-1)  # Add feature dimension\n",
    "        \n",
    "        # Project to d_model dimensions\n",
    "        x = self.input_projection(x)  # (batch, seq_len, d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.pos_encoding[:, :x.size(1), :].to(x.device)\n",
    "        \n",
    "        # Transformer encoding\n",
    "        x = self.transformer_encoder(x)  # (batch, seq_len, d_model)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = x.mean(dim=1)  # (batch, d_model)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)  # (batch, 1)\n",
    "        \n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# Also define LSTM baseline for comparison\n",
    "class LSTMFloodClassifier(nn.Module):\n",
    "    \"\"\"LSTM Baseline for comparison.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=1, hidden_dim=128, num_layers=2, dropout=0.2, bidirectional=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(-1)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = lstm_out[:, -1, :]  # Last timestep\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "MODEL_TYPE = 'transformer'  # Options: 'transformer', 'lstm'\n",
    "\n",
    "if MODEL_TYPE == 'transformer':\n",
    "    model = TransformerFloodClassifier(\n",
    "        input_dim=1,\n",
    "        d_model=D_MODEL,\n",
    "        nhead=N_HEADS,\n",
    "        num_layers=N_LAYERS,\n",
    "        dim_feedforward=D_MODEL * 4,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    print(\"Initialized: Transformer Flood Classifier\")\n",
    "else:\n",
    "    model = LSTMFloodClassifier(\n",
    "        input_dim=1,\n",
    "        hidden_dim=D_MODEL,\n",
    "        num_layers=N_LAYERS,\n",
    "        dropout=DROPOUT,\n",
    "        bidirectional=True\n",
    "    )\n",
    "    print(\"Initialized: LSTM Flood Classifier\")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: AdamW (lr={LEARNING_RATE}, weight_decay={WEIGHT_DECAY})\")\n",
    "print(f\"Scheduler: Linear warmup ({warmup_steps} steps) + decay\")\n",
    "print(f\"Total training steps: {total_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, scheduler, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        all_preds.extend(outputs.detach().cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, auc\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    pred_binary = (all_preds > 0.5).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': avg_loss,\n",
    "        'auc': roc_auc_score(all_labels, all_preds),\n",
    "        'accuracy': accuracy_score(all_labels, pred_binary),\n",
    "        'f1': f1_score(all_labels, pred_binary, zero_division=0),\n",
    "        'mcc': matthews_corrcoef(all_labels, pred_binary),\n",
    "        'rmse': np.sqrt(mean_squared_error(all_labels, all_preds)),\n",
    "        'mae': mean_absolute_error(all_labels, all_preds)\n",
    "    }\n",
    "    \n",
    "    return metrics, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop (with 50/50 Balance Strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_auc': [],\n",
    "    'val_loss': [], 'val_auc': [], 'val_f1': []\n",
    "}\n",
    "\n",
    "best_val_auc = 0\n",
    "best_model_state = None\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Epoch':>6} | {'Train Loss':>10} | {'Train AUC':>10} | {'Val Loss':>10} | {'Val AUC':>10} | {'Val F1':>10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # =========================================================================\n",
    "    # 50/50 BALANCE: Phase-based training\n",
    "    # Phase 1 (epochs 1-3): Could freeze backbone here if using pre-trained\n",
    "    # Phase 2 (epochs 4+): Full fine-tuning\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_auc = train_epoch(model, train_loader, criterion, optimizer, scheduler, DEVICE)\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics, _, _ = evaluate(model, val_loader, criterion, DEVICE)\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_auc'].append(train_auc)\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_auc'].append(val_metrics['auc'])\n",
    "    history['val_f1'].append(val_metrics['f1'])\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"{epoch+1:>6} | {train_loss:>10.4f} | {train_auc:>10.4f} | {val_metrics['loss']:>10.4f} | {val_metrics['auc']:>10.4f} | {val_metrics['f1']:>10.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['auc'] > best_val_auc:\n",
    "        best_val_auc = val_metrics['auc']\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "        print(f\"       *** New best model! AUC: {best_val_auc:.4f} ***\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"Best validation AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Evaluation & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "if best_model_state:\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "# Final evaluation\n",
    "final_metrics, val_preds, val_labels = evaluate(model, val_loader, criterion, DEVICE)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL EVALUATION ON VALIDATION SET (20%)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nROC AUC:  {final_metrics['auc']:.4f}\")\n",
    "print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1 Score: {final_metrics['f1']:.4f}\")\n",
    "print(f\"MCC:      {final_metrics['mcc']:.4f}\")\n",
    "print(f\"RMSE:     {final_metrics['rmse']:.4f}\")\n",
    "print(f\"MAE:      {final_metrics['mae']:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "pred_binary = (val_preds > 0.5).astype(int)\n",
    "cm = confusion_matrix(val_labels, pred_binary)\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  Predicted:  No Flood    Flood\")\n",
    "print(f\"  Actual:\")\n",
    "print(f\"  No Flood    {cm[0,0]:>7}  {cm[0,1]:>7}\")\n",
    "print(f\"  Flood       {cm[1,0]:>7}  {cm[1,1]:>7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Validation')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# AUC\n",
    "axes[1].plot(history['train_auc'], label='Train')\n",
    "axes[1].plot(history['val_auc'], label='Validation')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('AUC')\n",
    "axes[1].set_title('Training & Validation AUC')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# F1\n",
    "axes[2].plot(history['val_f1'], label='Validation F1', color='green')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].set_title('Validation F1 Score')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# 14.5 FINAL EVALUATION WITH WEIGHTED MODEL\n# =============================================================================\n\n# Load best weighted model\nif best_model_weighted_state:\n    model_weighted.load_state_dict(best_model_weighted_state)\n\n# Get final predictions\nmodel_weighted.eval()\nfinal_logits = []\nfinal_labels = []\n\nwith torch.no_grad():\n    for batch_x, batch_y in val_loader:\n        batch_x = batch_x.to(DEVICE)\n        logits = model_weighted(batch_x)\n        final_logits.extend(logits.cpu().numpy())\n        final_labels.extend(batch_y.numpy())\n\nfinal_logits = np.array(final_logits)\nfinal_probs_weighted = 1 / (1 + np.exp(-final_logits))  # Sigmoid\nfinal_labels = np.array(final_labels)\n\n# Run comprehensive evaluation\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL EVALUATION: WEIGHTED MODEL\")\nprint(\"=\"*80)\n\neval_results_weighted = comprehensive_evaluation(final_labels, final_probs_weighted, \n                                                  \"Weighted Model Final Evaluation\")\n\n# Print confusion matrices\nprint_confusion_matrix(final_labels, final_probs_weighted, 0.5, \"Default Threshold (0.5)\")\nprint_confusion_matrix(final_labels, final_probs_weighted, \n                       eval_results_weighted['best_threshold'], \"Best F1 Threshold\")\n\n# Final comparison\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY: BEFORE vs AFTER IMBALANCE HANDLING\")\nprint(\"=\"*80)\nprint(f\"\\n{'Metric':<20} {'Before (Standard BCE)':<25} {'After (Weighted BCE)':<25}\")\nprint(\"-\"*70)\nprint(f\"{'ROC-AUC':<20} {eval_results['roc_auc']:<25.4f} {eval_results_weighted['roc_auc']:<25.4f}\")\nprint(f\"{'PR-AUC':<20} {eval_results['pr_auc']:<25.4f} {eval_results_weighted['pr_auc']:<25.4f}\")\nprint(f\"{'F1 @ 0.5':<20} {eval_results['f1_at_0.5']:<25.4f} {eval_results_weighted['f1_at_0.5']:<25.4f}\")\nprint(f\"{'F1 Best':<20} {eval_results['f1_best']:<25.4f} {eval_results_weighted['f1_best']:<25.4f}\")\nprint(f\"{'Best Threshold':<20} {eval_results['best_threshold']:<25.2f} {eval_results_weighted['best_threshold']:<25.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# 14.4 VERIFY F1 IS NO LONGER CONSTANT - PLOT COMPARISON\n# =============================================================================\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\n\n# Row 1: Training metrics over epochs\naxes[0, 0].plot(history_weighted['roc_auc'], 'b-', linewidth=2, label='ROC-AUC')\naxes[0, 0].plot(history_weighted['pr_auc'], 'g-', linewidth=2, label='PR-AUC')\naxes[0, 0].set_xlabel('Epoch')\naxes[0, 0].set_ylabel('Score')\naxes[0, 0].set_title('ROC-AUC & PR-AUC Over Training')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(history_weighted['f1_at_0.5'], 'r-', linewidth=2, label='F1 @ 0.5')\naxes[0, 1].plot(history_weighted['f1_best'], 'b-', linewidth=2, label='F1 Best')\naxes[0, 1].set_xlabel('Epoch')\naxes[0, 1].set_ylabel('F1 Score')\naxes[0, 1].set_title('F1 Scores Over Training (SHOULD NOT BE FLAT!)')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\naxes[0, 2].plot(history_weighted['best_threshold'], 'purple', linewidth=2)\naxes[0, 2].axhline(y=0.5, color='gray', linestyle='--', label='Default (0.5)')\naxes[0, 2].set_xlabel('Epoch')\naxes[0, 2].set_ylabel('Best Threshold')\naxes[0, 2].set_title('Optimal Threshold Over Training')\naxes[0, 2].legend()\naxes[0, 2].grid(True, alpha=0.3)\n\n# Row 2: Loss\naxes[1, 0].plot(history_weighted['train_loss'], 'b-', linewidth=2, label='Train')\naxes[1, 0].plot(history_weighted['val_loss'], 'r-', linewidth=2, label='Validation')\naxes[1, 0].set_xlabel('Epoch')\naxes[1, 0].set_ylabel('Loss')\naxes[1, 0].set_title('Training & Validation Loss')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Compare old vs new F1\nif len(history['val_f1']) > 0 and len(history_weighted['f1_best']) > 0:\n    axes[1, 1].plot(history['val_f1'], 'r--', linewidth=2, label='Old (Standard BCE)', alpha=0.7)\n    axes[1, 1].plot(history_weighted['f1_best'], 'b-', linewidth=2, label='New (Weighted BCE)')\n    axes[1, 1].set_xlabel('Epoch')\n    axes[1, 1].set_ylabel('F1 Score')\n    axes[1, 1].set_title('F1 Comparison: Before vs After Fix')\n    axes[1, 1].legend()\n    axes[1, 1].grid(True, alpha=0.3)\n\n# Verification message\naxes[1, 2].axis('off')\nf1_range = max(history_weighted['f1_best']) - min(history_weighted['f1_best'])\nf1_is_constant = f1_range < 0.01\n\nif f1_is_constant:\n    status = \"⚠️ F1 still appears constant!\"\n    color = 'red'\nelse:\n    status = \"✅ F1 is now varying (not constant)\"\n    color = 'green'\n\nverification_text = f\"\"\"\nVERIFICATION RESULTS\n═══════════════════════════════════════\n\n{status}\n\nF1 Range: {min(history_weighted['f1_best']):.4f} - {max(history_weighted['f1_best']):.4f}\nF1 Variance: {np.var(history_weighted['f1_best']):.6f}\n\nFinal Metrics:\n  • ROC-AUC: {history_weighted['roc_auc'][-1]:.4f}\n  • PR-AUC:  {history_weighted['pr_auc'][-1]:.4f}\n  • F1 Best: {history_weighted['f1_best'][-1]:.4f}\n  • Optimal Threshold: {history_weighted['best_threshold'][-1]:.2f}\n\nBest PR-AUC achieved: {best_pr_auc:.4f}\n\"\"\"\n\naxes[1, 2].text(0.1, 0.5, verification_text, transform=axes[1, 2].transAxes,\n                fontsize=12, verticalalignment='center', fontfamily='monospace',\n                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nplt.tight_layout()\nplt.savefig('weighted_training_results.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\n✅ Saved weighted training results to: weighted_training_results.png\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# 14.3 RETRAIN WITH WEIGHTED LOSS\n# =============================================================================\n\n# Setup optimizer\noptimizer_weighted = optim.AdamW(\n    model_weighted.parameters(),\n    lr=LEARNING_RATE,\n    weight_decay=WEIGHT_DECAY\n)\n\n# Scheduler\ntotal_steps_w = len(train_loader) * EPOCHS\nscheduler_weighted = get_linear_schedule_with_warmup(\n    optimizer_weighted,\n    num_warmup_steps=int(total_steps_w * WARMUP_RATIO),\n    num_training_steps=total_steps_w\n)\n\n# Training tracking\nhistory_weighted = {\n    'train_loss': [], 'val_loss': [],\n    'roc_auc': [], 'pr_auc': [],\n    'f1_at_0.5': [], 'f1_best': [], 'best_threshold': []\n}\n\nbest_pr_auc = 0\nbest_model_weighted_state = None\npatience_counter_w = 0\n\nprint(\"=\"*80)\nprint(\"TRAINING WITH WEIGHTED LOSS (BCEWithLogitsLoss)\")\nprint(\"=\"*80)\nprint(f\"pos_weight = {pos_weight_value:.4f}\")\nprint(f\"\\n{'Epoch':>5} | {'Train Loss':>10} | {'Val Loss':>10} | {'ROC-AUC':>8} | {'PR-AUC':>8} | {'F1@0.5':>8} | {'F1 Best':>8} | {'Thresh':>7}\")\nprint(\"-\"*80)\n\nfor epoch in range(EPOCHS):\n    # TRAINING\n    model_weighted.train()\n    train_loss = 0\n    \n    for batch_x, batch_y in train_loader:\n        batch_x = batch_x.to(DEVICE)\n        batch_y = batch_y.to(DEVICE)\n        \n        optimizer_weighted.zero_grad()\n        logits = model_weighted(batch_x)  # Output is LOGITS\n        loss = weighted_criterion(logits, batch_y)\n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model_weighted.parameters(), max_norm=1.0)\n        optimizer_weighted.step()\n        scheduler_weighted.step()\n        \n        train_loss += loss.item()\n    \n    train_loss /= len(train_loader)\n    \n    # VALIDATION\n    model_weighted.eval()\n    val_loss = 0\n    all_logits = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch_x, batch_y in val_loader:\n            batch_x = batch_x.to(DEVICE)\n            batch_y = batch_y.to(DEVICE)\n            \n            logits = model_weighted(batch_x)\n            loss = weighted_criterion(logits, batch_y)\n            \n            val_loss += loss.item()\n            all_logits.extend(logits.cpu().numpy())\n            all_labels.extend(batch_y.cpu().numpy())\n    \n    val_loss /= len(val_loader)\n    \n    # Convert logits to probabilities using sigmoid\n    all_logits = np.array(all_logits)\n    all_probs = 1 / (1 + np.exp(-all_logits))  # Sigmoid\n    all_labels = np.array(all_labels)\n    \n    # Compute metrics\n    roc_auc = roc_auc_score(all_labels, all_probs)\n    pr_auc = average_precision_score(all_labels, all_probs)\n    \n    # F1 at 0.5\n    f1_05 = f1_score(all_labels, (all_probs >= 0.5).astype(int), zero_division=0)\n    \n    # Find best F1 threshold\n    thresholds = np.arange(0.01, 1.0, 0.01)\n    f1_scores = [f1_score(all_labels, (all_probs >= t).astype(int), zero_division=0) for t in thresholds]\n    best_idx = np.argmax(f1_scores)\n    best_f1 = f1_scores[best_idx]\n    best_thresh = thresholds[best_idx]\n    \n    # Record history\n    history_weighted['train_loss'].append(train_loss)\n    history_weighted['val_loss'].append(val_loss)\n    history_weighted['roc_auc'].append(roc_auc)\n    history_weighted['pr_auc'].append(pr_auc)\n    history_weighted['f1_at_0.5'].append(f1_05)\n    history_weighted['f1_best'].append(best_f1)\n    history_weighted['best_threshold'].append(best_thresh)\n    \n    # Print progress\n    print(f\"{epoch+1:>5} | {train_loss:>10.4f} | {val_loss:>10.4f} | {roc_auc:>8.4f} | {pr_auc:>8.4f} | {f1_05:>8.4f} | {best_f1:>8.4f} | {best_thresh:>7.2f}\")\n    \n    # Save best model (by PR-AUC, better for imbalanced data)\n    if pr_auc > best_pr_auc:\n        best_pr_auc = pr_auc\n        best_model_weighted_state = model_weighted.state_dict().copy()\n        patience_counter_w = 0\n        print(f\"      *** New best PR-AUC: {pr_auc:.4f} ***\")\n    else:\n        patience_counter_w += 1\n    \n    # Early stopping\n    if patience_counter_w >= PATIENCE:\n        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n        break\n\nprint(\"=\"*80)\nprint(\"TRAINING COMPLETE\")\nprint(f\"Best PR-AUC: {best_pr_auc:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# 14.2 MODIFIED MODEL FOR BCEWithLogitsLoss (NO SIGMOID IN FORWARD)\n# =============================================================================\n\nclass TransformerFloodClassifierLogits(nn.Module):\n    \"\"\"\n    Transformer for Flood Classification - OUTPUTS LOGITS (no sigmoid)\n    \n    Required for BCEWithLogitsLoss which applies sigmoid internally.\n    This is more numerically stable.\n    \"\"\"\n    \n    def __init__(\n        self,\n        input_dim=1,\n        d_model=128,\n        nhead=8,\n        num_layers=4,\n        dim_feedforward=512,\n        dropout=0.1,\n        max_seq_len=100\n    ):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.input_projection = nn.Linear(input_dim, d_model)\n        \n        # Positional encoding\n        pe = torch.zeros(max_seq_len, d_model)\n        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        self.pos_encoding = nn.Parameter(pe.unsqueeze(0), requires_grad=False)\n        \n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        \n        # Classification head - NO SIGMOID (outputs logits)\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model, d_model // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model // 2, 1)  # Output raw logits\n        )\n    \n    def forward(self, x):\n        if x.dim() == 2:\n            x = x.unsqueeze(-1)\n        \n        x = self.input_projection(x)\n        x = x + self.pos_encoding[:, :x.size(1), :].to(x.device)\n        x = self.transformer_encoder(x)\n        x = x.mean(dim=1)\n        x = self.classifier(x)\n        \n        return x.squeeze(-1)  # Returns LOGITS, not probabilities\n\n# Initialize new model\nmodel_weighted = TransformerFloodClassifierLogits(\n    input_dim=1,\n    d_model=D_MODEL,\n    nhead=N_HEADS,\n    num_layers=N_LAYERS,\n    dim_feedforward=D_MODEL * 4,\n    dropout=DROPOUT\n).to(DEVICE)\n\nprint(\"✅ Initialized TransformerFloodClassifierLogits (outputs logits, not probabilities)\")\nprint(f\"   Total parameters: {sum(p.numel() for p in model_weighted.parameters()):,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# 14.1 COMPUTE CORRECT POS_WEIGHT FOR IMBALANCE HANDLING\n# =============================================================================\n\n# Calculate class weights based on actual class distribution\nn_positive = y_train.sum()\nn_negative = len(y_train) - n_positive\n\nprint(\"=\"*70)\nprint(\"IMBALANCE HANDLING SETUP\")\nprint(\"=\"*70)\n\nprint(f\"\\nClass distribution in training set:\")\nprint(f\"   Positive (label=1, FLOOD):     {n_positive:,} ({n_positive/len(y_train)*100:.1f}%)\")\nprint(f\"   Negative (label=0, NO FLOOD):  {n_negative:,} ({n_negative/len(y_train)*100:.1f}%)\")\n\n# Determine which weighting approach to use\nif n_positive > n_negative:\n    # FLOOD is majority, NO FLOOD is rare\n    # We want to UPWEIGHT the rare class (NO FLOOD = label 0)\n    # In BCEWithLogitsLoss, pos_weight < 1 effectively upweights negatives\n    pos_weight_value = n_negative / n_positive\n    print(f\"\\n⚖️  MAJORITY class: FLOOD (label=1)\")\n    print(f\"   RARE class: NO FLOOD (label=0)\")\n    print(f\"\\n   pos_weight = n_neg / n_pos = {n_negative} / {n_positive} = {pos_weight_value:.4f}\")\n    print(f\"\\n   Interpretation: pos_weight < 1 means we DOWNWEIGHT positive class,\")\n    print(f\"   which effectively UPWEIGHTS the rare negative class.\")\nelse:\n    # NO FLOOD is majority, FLOOD is rare\n    # We want to UPWEIGHT the rare class (FLOOD = label 1)\n    pos_weight_value = n_negative / n_positive\n    print(f\"\\n⚖️  MAJORITY class: NO FLOOD (label=0)\")\n    print(f\"   RARE class: FLOOD (label=1)\")\n    print(f\"\\n   pos_weight = n_neg / n_pos = {n_negative} / {n_positive} = {pos_weight_value:.4f}\")\n    print(f\"\\n   Interpretation: pos_weight > 1 means we UPWEIGHT positive (rare) class.\")\n\n# Create the weighted loss\npos_weight_tensor = torch.tensor([pos_weight_value]).to(DEVICE)\nweighted_criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n\nprint(f\"\\n✅ Created BCEWithLogitsLoss with pos_weight = {pos_weight_value:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 14. Imbalance Handling\n\n### Problem Identified\nFrom the class balance report above, we see that **label=1 (FLOOD) is the MAJORITY class** (~87.8%).\n\nThis means:\n- The model can achieve ~93.5% F1 by predicting ALL 1s (floods)\n- Standard BCE loss doesn't penalize this behavior enough\n- We need to **upweight the RARE class (label=0, No Flood)**\n\n### Solution: Weighted Loss Function\n\nWe'll use `BCEWithLogitsLoss` with `pos_weight` parameter:\n\n```python\npos_weight = n_negative / n_positive  # e.g., 0.139 if 87.8% positive\n```\n\n**Important**: In PyTorch's BCEWithLogitsLoss:\n- `pos_weight > 1` → upweights the POSITIVE class (label=1)\n- `pos_weight < 1` → effectively upweights the NEGATIVE class (label=0)\n\nSince our RARE class is label=0 (No Flood), we need `pos_weight < 1`:\n```python\npos_weight = n_negative / n_positive = 0.139  # This downweights label=1\n```\n\nThis makes the model pay MORE attention to correctly classifying the rare \"No Flood\" events.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# 13.4 CONFUSION MATRICES AT DIFFERENT THRESHOLDS\n# =============================================================================\nfrom sklearn.metrics import precision_score, recall_score\n\ndef print_confusion_matrix(y_true, y_prob, threshold, name):\n    \"\"\"Print detailed confusion matrix at a given threshold.\"\"\"\n    y_pred = (y_prob >= threshold).astype(int)\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Handle edge cases\n    if cm.shape == (1, 1):\n        print(f\"\\n⚠️  All predictions are the same class at threshold {threshold:.2f}\")\n        return\n    \n    tn, fp, fn, tp = cm.ravel()\n    \n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"CONFUSION MATRIX: {name} (threshold = {threshold:.3f})\")\n    print(f\"{'='*60}\")\n    print(f\"\\n                    Predicted\")\n    print(f\"                 No Flood    Flood\")\n    print(f\"Actual No Flood   {tn:>7}   {fp:>7}   (Specificity: {specificity:.2%})\")\n    print(f\"       Flood      {fn:>7}   {tp:>7}   (Recall: {recall:.2%})\")\n    print(f\"\\n   True Negatives (TN):  {tn:>7}  - Correctly predicted No Flood\")\n    print(f\"   False Positives (FP): {fp:>7}  - Incorrectly predicted Flood\")\n    print(f\"   False Negatives (FN): {fn:>7}  - Missed Floods (DANGEROUS!)\")\n    print(f\"   True Positives (TP):  {tp:>7}  - Correctly predicted Flood\")\n    print(f\"\\n   Precision: {precision:.4f}  (Of predicted floods, how many were real?)\")\n    print(f\"   Recall:    {recall:.4f}  (Of real floods, how many did we catch?)\")\n    print(f\"   F1 Score:  {f1:.4f}\")\n\n# Print confusion matrices at different thresholds\nprint_confusion_matrix(val_labels, val_preds, 0.5, \"Default Threshold (0.5)\")\nprint_confusion_matrix(val_labels, val_preds, eval_results['best_threshold'], \"Best F1 Threshold\")\n\n# Also show what happens at extreme thresholds to verify predictions aren't constant\nprint_confusion_matrix(val_labels, val_preds, 0.1, \"Low Threshold (0.1)\")\nprint_confusion_matrix(val_labels, val_preds, 0.9, \"High Threshold (0.9)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# 13.3 PLOT ROC CURVE, PR CURVE, F1 VS THRESHOLD\n# =============================================================================\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# 1. ROC Curve\nfpr, tpr, _ = roc_curve(val_labels, val_preds)\nroc_auc = eval_results['roc_auc']\n\naxes[0, 0].plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\naxes[0, 0].plot([0, 1], [0, 1], 'r--', linewidth=1, label='Random Classifier')\naxes[0, 0].fill_between(fpr, tpr, alpha=0.3)\naxes[0, 0].set_xlabel('False Positive Rate', fontsize=12)\naxes[0, 0].set_ylabel('True Positive Rate', fontsize=12)\naxes[0, 0].set_title('ROC Curve', fontsize=14)\naxes[0, 0].legend(loc='lower right')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_xlim([0, 1])\naxes[0, 0].set_ylim([0, 1])\n\n# 2. Precision-Recall Curve\nprecision_curve, recall_curve, _ = precision_recall_curve(val_labels, val_preds)\npr_auc = eval_results['pr_auc']\nbaseline = val_labels.mean()\n\naxes[0, 1].plot(recall_curve, precision_curve, 'b-', linewidth=2, label=f'PR Curve (AP = {pr_auc:.4f})')\naxes[0, 1].axhline(y=baseline, color='r', linestyle='--', linewidth=1, label=f'Baseline ({baseline:.4f})')\naxes[0, 1].fill_between(recall_curve, precision_curve, alpha=0.3)\naxes[0, 1].set_xlabel('Recall', fontsize=12)\naxes[0, 1].set_ylabel('Precision', fontsize=12)\naxes[0, 1].set_title('Precision-Recall Curve', fontsize=14)\naxes[0, 1].legend(loc='lower left')\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xlim([0, 1])\naxes[0, 1].set_ylim([0, 1])\n\n# 3. F1 vs Threshold\nthresholds = eval_results['thresholds']\nf1_scores = eval_results['f1_scores']\nbest_threshold = eval_results['best_threshold']\n\naxes[1, 0].plot(thresholds, f1_scores, 'b-', linewidth=2, label='F1 Score')\naxes[1, 0].axvline(x=best_threshold, color='r', linestyle='--', linewidth=2, \n                   label=f'Best Threshold = {best_threshold:.2f}')\naxes[1, 0].axvline(x=0.5, color='g', linestyle=':', linewidth=2, label='Default (0.5)')\naxes[1, 0].scatter([best_threshold], [eval_results['f1_best']], color='r', s=100, zorder=5)\naxes[1, 0].set_xlabel('Threshold', fontsize=12)\naxes[1, 0].set_ylabel('F1 Score', fontsize=12)\naxes[1, 0].set_title('F1 Score vs Classification Threshold', fontsize=14)\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_xlim([0, 1])\n\n# 4. Probability Distribution by Class\naxes[1, 1].hist(val_preds[val_labels == 0], bins=50, alpha=0.6, label='No Flood (label=0)', \n                color='green', density=True)\naxes[1, 1].hist(val_preds[val_labels == 1], bins=50, alpha=0.6, label='Flood (label=1)', \n                color='red', density=True)\naxes[1, 1].axvline(x=best_threshold, color='black', linestyle='--', linewidth=2, \n                   label=f'Best Threshold = {best_threshold:.2f}')\naxes[1, 1].axvline(x=0.5, color='gray', linestyle=':', linewidth=2, label='Default (0.5)')\naxes[1, 1].set_xlabel('Predicted Probability', fontsize=12)\naxes[1, 1].set_ylabel('Density', fontsize=12)\naxes[1, 1].set_title('Probability Distribution by True Class', fontsize=14)\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('evaluation_curves.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\n✅ Saved evaluation curves to: evaluation_curves.png\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# 13.2 COMPREHENSIVE EVALUATION METRICS\n# =============================================================================\n\ndef comprehensive_evaluation(y_true, y_prob, title=\"Evaluation\"):\n    \"\"\"\n    Compute comprehensive evaluation metrics.\n    \n    Returns dict with:\n    - ROC-AUC\n    - PR-AUC (Average Precision)\n    - F1 at threshold=0.5\n    - Best F1 and optimal threshold\n    - Precision/Recall at various thresholds\n    \"\"\"\n    results = {}\n    \n    # Ensure probabilities are valid (between 0 and 1)\n    y_prob = np.clip(y_prob, 0, 1)\n    \n    # Check for degenerate predictions\n    print(f\"\\n{'='*70}\")\n    print(f\"{title.upper()}\")\n    print(f\"{'='*70}\")\n    \n    print(f\"\\n🔍 PROBABILITY DISTRIBUTION CHECK:\")\n    print(f\"   Min probability:  {y_prob.min():.4f}\")\n    print(f\"   Max probability:  {y_prob.max():.4f}\")\n    print(f\"   Mean probability: {y_prob.mean():.4f}\")\n    print(f\"   Std probability:  {y_prob.std():.4f}\")\n    \n    if y_prob.std() < 0.01:\n        print(f\"\\n   ⚠️  WARNING: Predictions have very low variance!\")\n        print(f\"   Model may be predicting nearly constant values.\")\n    \n    # 1. ROC-AUC\n    results['roc_auc'] = roc_auc_score(y_true, y_prob)\n    \n    # 2. PR-AUC (Average Precision) - better for imbalanced data\n    results['pr_auc'] = average_precision_score(y_true, y_prob)\n    \n    # 3. F1 at threshold=0.5\n    y_pred_05 = (y_prob >= 0.5).astype(int)\n    results['f1_at_0.5'] = f1_score(y_true, y_pred_05, zero_division=0)\n    results['precision_at_0.5'] = precision_score(y_true, y_pred_05, zero_division=0)\n    results['recall_at_0.5'] = recall_score(y_true, y_pred_05, zero_division=0)\n    \n    # 4. Find optimal threshold for F1\n    thresholds = np.arange(0.01, 1.0, 0.01)\n    f1_scores = []\n    \n    for thresh in thresholds:\n        y_pred = (y_prob >= thresh).astype(int)\n        f1 = f1_score(y_true, y_pred, zero_division=0)\n        f1_scores.append(f1)\n    \n    best_idx = np.argmax(f1_scores)\n    results['best_threshold'] = thresholds[best_idx]\n    results['f1_best'] = f1_scores[best_idx]\n    \n    # Metrics at best threshold\n    y_pred_best = (y_prob >= results['best_threshold']).astype(int)\n    results['precision_at_best'] = precision_score(y_true, y_pred_best, zero_division=0)\n    results['recall_at_best'] = recall_score(y_true, y_pred_best, zero_division=0)\n    results['accuracy_at_best'] = accuracy_score(y_true, y_pred_best)\n    \n    # Print results\n    print(f\"\\n📈 METRICS:\")\n    print(f\"   ROC-AUC:          {results['roc_auc']:.4f}\")\n    print(f\"   PR-AUC (AP):      {results['pr_auc']:.4f}  ← Better for imbalanced data!\")\n    print(f\"\\n   F1 @ threshold=0.5:\")\n    print(f\"      F1:        {results['f1_at_0.5']:.4f}\")\n    print(f\"      Precision: {results['precision_at_0.5']:.4f}\")\n    print(f\"      Recall:    {results['recall_at_0.5']:.4f}\")\n    print(f\"\\n   F1 @ BEST threshold={results['best_threshold']:.2f}:\")\n    print(f\"      F1:        {results['f1_best']:.4f}\")\n    print(f\"      Precision: {results['precision_at_best']:.4f}\")\n    print(f\"      Recall:    {results['recall_at_best']:.4f}\")\n    print(f\"      Accuracy:  {results['accuracy_at_best']:.4f}\")\n    \n    # Store for plotting\n    results['thresholds'] = thresholds\n    results['f1_scores'] = f1_scores\n    \n    return results\n\n# Run comprehensive evaluation on validation predictions\neval_results = comprehensive_evaluation(val_labels, val_preds, \"Validation Set Evaluation\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# 13.1 CLASS BALANCE REPORT & LABEL DEFINITION\n# =============================================================================\nfrom sklearn.metrics import precision_recall_curve, roc_curve, average_precision_score\n\nprint(\"=\"*70)\nprint(\"CLASS BALANCE REPORT\")\nprint(\"=\"*70)\n\n# Training set\ntrain_pos = y_train.sum()\ntrain_neg = len(y_train) - train_pos\ntrain_pos_rate = y_train.mean()\n\n# Validation set  \nval_pos = y_val.sum()\nval_neg = len(y_val) - val_pos\nval_pos_rate = y_val.mean()\n\nprint(f\"\\n📊 TRAINING SET:\")\nprint(f\"   Total samples:     {len(y_train):,}\")\nprint(f\"   Positive (label=1): {train_pos:,} ({train_pos_rate*100:.1f}%)\")\nprint(f\"   Negative (label=0): {train_neg:,} ({(1-train_pos_rate)*100:.1f}%)\")\n\nprint(f\"\\n📊 VALIDATION SET:\")\nprint(f\"   Total samples:     {len(y_val):,}\")\nprint(f\"   Positive (label=1): {val_pos:,} ({val_pos_rate*100:.1f}%)\")\nprint(f\"   Negative (label=0): {val_neg:,} ({(1-val_pos_rate)*100:.1f}%)\")\n\n# Compute pos_weight for weighted loss\npos_weight = train_neg / train_pos\nprint(f\"\\n⚖️  RECOMMENDED pos_weight: {pos_weight:.4f}\")\nprint(f\"   (Use this in BCEWithLogitsLoss to upweight the RARE class)\")\n\n# Explicitly state what label=1 means\nprint(f\"\\n\" + \"=\"*70)\nprint(\"LABEL DEFINITION (from notebook code)\")\nprint(\"=\"*70)\nprint(\"\"\"\n📝 label=1 means: FLOOD EVENT\n   - Defined in create_sequences(): label = int(future_floods.max() > 0)\n   - A sample is labeled 1 if ANY day in the next 14 days has flooding\n   - Flooding = daily max sea level > station's flood threshold\n   - Threshold = mean + 1.5 × std of sea level per station\n\n📝 label=0 means: NO FLOOD\n   - No flooding event in the 14-day prediction window\n\"\"\")\n\n# Identify which class is RARE\nif train_pos_rate > 0.5:\n    rare_class = 0\n    rare_name = \"NO FLOOD\"\n    majority_name = \"FLOOD\"\nelse:\n    rare_class = 1\n    rare_name = \"FLOOD\"\n    majority_name = \"NO FLOOD\"\n\nprint(f\"\\n⚠️  CLASS IMBALANCE DETECTED:\")\nprint(f\"   RARE class:     label={rare_class} ({rare_name}) - {min(train_pos_rate, 1-train_pos_rate)*100:.1f}%\")\nprint(f\"   MAJORITY class: label={1-rare_class} ({majority_name}) - {max(train_pos_rate, 1-train_pos_rate)*100:.1f}%\")\nprint(f\"\\n   The model is likely predicting ALL {majority_name} to get high F1!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 13. Evaluation Fixes\n\nThis section addresses the issue of **constant F1 score (~0.935)** and **low ROC-AUC (~0.56)** by:\n\n1. Computing proper metrics: ROC-AUC, PR-AUC (better for imbalanced data)\n2. Finding optimal classification threshold (not just 0.5)\n3. Plotting ROC curve, PR curve, and F1 vs threshold\n4. Showing confusion matrices at multiple thresholds\n5. Reporting class balance to understand the imbalance\n\n**Why F1 was constant**: With 87.8% positive class, predicting ALL 1s gives F1 ≈ 0.935. The model wasn't learning - it was just predicting the majority class!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comparison with XGBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost baseline results from overnight training\n",
    "xgboost_baseline = {\n",
    "    'auc': 0.7676,\n",
    "    'f1': 0.8105,\n",
    "    'accuracy': 0.78,\n",
    "    'mcc': 0.27\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARISON: TRANSFORMER vs XGBOOST BASELINE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'Metric':<12} {'XGBoost':<12} {'Transformer':<12} {'Difference':<12}\")\n",
    "print(\"-\"*48)\n",
    "\n",
    "for metric in ['auc', 'f1', 'accuracy', 'mcc']:\n",
    "    xgb_val = xgboost_baseline.get(metric, 0)\n",
    "    trans_val = final_metrics.get(metric, 0)\n",
    "    diff = trans_val - xgb_val\n",
    "    sign = '+' if diff > 0 else ''\n",
    "    print(f\"{metric:<12} {xgb_val:<12.4f} {trans_val:<12.4f} {sign}{diff:.4f}\")\n",
    "\n",
    "print(\"\\nNote: Positive difference means Transformer outperformed XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Model & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': best_model_state,\n",
    "    'model_config': {\n",
    "        'model_type': MODEL_TYPE,\n",
    "        'd_model': D_MODEL,\n",
    "        'num_layers': N_LAYERS,\n",
    "        'nhead': N_HEADS,\n",
    "        'dropout': DROPOUT\n",
    "    },\n",
    "    'metrics': final_metrics,\n",
    "    'history': history\n",
    "}, 'best_transformer_model.pt')\n",
    "\n",
    "print(\"Model saved to: best_transformer_model.pt\")\n",
    "\n",
    "# Download the model\n",
    "from google.colab import files\n",
    "files.download('best_transformer_model.pt')\n",
    "files.download('training_history.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary for Homework Report\n",
    "\n",
    "### Model Architecture\n",
    "- **Type**: Transformer Encoder with Classification Head\n",
    "- **Hidden Dimension (d_model)**: 128\n",
    "- **Attention Heads**: 8\n",
    "- **Encoder Layers**: 4\n",
    "- **Feedforward Dimension**: 512\n",
    "- **Dropout**: 0.1\n",
    "- **Total Parameters**: ~500K\n",
    "\n",
    "### Hyperparameters\n",
    "- **Learning Rate**: 1e-4 (low for fine-tuning stability)\n",
    "- **Batch Size**: 64\n",
    "- **Weight Decay**: 0.01 (L2 regularization)\n",
    "- **Warmup Ratio**: 0.1\n",
    "- **Early Stopping Patience**: 10 epochs\n",
    "\n",
    "### Training Strategy\n",
    "1. **Data Split**: 80% training / 20% validation (stratified)\n",
    "2. **Normalization**: Z-score per sequence\n",
    "3. **Optimizer**: AdamW with linear warmup + decay\n",
    "4. **Loss**: Binary Cross-Entropy\n",
    "5. **50/50 Balance**: Low learning rate preserves general patterns while adapting to domain\n",
    "\n",
    "### Design Rationale\n",
    "1. **Transformer over RNN**: Self-attention captures long-range temporal dependencies more effectively than recurrent architectures\n",
    "2. **Positional Encoding**: Sinusoidal encoding injects sequence order information\n",
    "3. **Global Pooling**: Aggregates variable-length sequence information for classification\n",
    "4. **Transfer Learning Ready**: Architecture designed to accept pre-trained weights (Chronos, TimeGPT, etc.)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}